{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. Prueba de Modelos SAM 3 (REAL) - FIXED\n",
                "\n",
                "**Objetivo:** Evaluar el nuevo modelo **SAM 3** (lanzado en Noviembre 2025) para determinar si sus capacidades avanzadas de segmentación mejoran el refinamiento de detecciones de corrosión.\n",
                "\n",
                "## Novedades de SAM 3\n",
                "- **Promptable Concept Segmentation:** Capacidad de entender conceptos visuales.\n",
                "- **Mejor Segmentación Interactiva:** Supera a SAM 2 en precisión.\n",
                "- **Arquitectura Unificada:** Mejor manejo de contexto.\n",
                "\n",
                "## Metodología\n",
                "1. **Modelo:** Uso de `sam3_b.pt` (Base) o `sam3_t.pt` (Tiny) para evitar errores de memoria.\n",
                "2. **Correcciones:** Incluye todos los fixes previos (conf=0.25, caché, etc.)\n",
                "3. **Comparación:** Se evaluará contra YOLO Base y SAM 2.1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "ERROR: Exception:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
                        "    yield\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
                        "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
                        "           ~~~~~~~~~~~~~^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
                        "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
                        "           ~~~~~~~~~~~~~^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 102, in read\n",
                        "    self.__buf.write(data)\n",
                        "    ~~~~~~~~~~~~~~~~^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\tempfile.py\", line 499, in func_wrapper\n",
                        "    return func(*args, **kwargs)\n",
                        "OSError: [Errno 28] No space left on device\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
                        "    status = _inner_run()\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
                        "    return self.run(options, args)\n",
                        "           ~~~~~~~~^^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 68, in wrapper\n",
                        "    return func(self, options, args)\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 387, in run\n",
                        "    requirement_set = resolver.resolve(\n",
                        "        reqs, check_supported_wheels=not options.target_dir\n",
                        "    )\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 182, in resolve\n",
                        "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 559, in prepare_linked_requirements_more\n",
                        "    self._complete_partial_requirements(\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
                        "        partially_downloaded_reqs,\n",
                        "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "        parallel_builds=parallel_builds,\n",
                        "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "    )\n",
                        "    ^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 474, in _complete_partial_requirements\n",
                        "    for link, (filepath, _) in batch_download:\n",
                        "                               ^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 313, in __call__\n",
                        "    filepath, content_type = self._downloader(link, location)\n",
                        "                             ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 185, in __call__\n",
                        "    bytes_received = self._process_response(\n",
                        "        resp, link, content_file, 0, total_length\n",
                        "    )\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 208, in _process_response\n",
                        "    return self._write_chunks_to_file(\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
                        "        chunks, content_file, allow_partial=bool(total_length)\n",
                        "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "    )\n",
                        "    ^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 218, in _write_chunks_to_file\n",
                        "    for chunk in chunks:\n",
                        "                 ^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
                        "    for chunk in response.raw.stream(\n",
                        "                 ~~~~~~~~~~~~~~~~~~~^\n",
                        "        chunk_size,\n",
                        "        ^^^^^^^^^^^\n",
                        "    ...<22 lines>...\n",
                        "        decode_content=False,\n",
                        "        ^^^^^^^^^^^^^^^^^^^^^\n",
                        "    ):\n",
                        "    ^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
                        "    data = self.read(amt=amt, decode_content=decode_content)\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
                        "    with self._error_catcher():\n",
                        "         ~~~~~~~~~~~~~~~~~~~^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\contextlib.py\", line 162, in __exit__\n",
                        "    self.gen.throw(value)\n",
                        "    ~~~~~~~~~~~~~~^^^^^^^\n",
                        "  File \"C:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
                        "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
                        "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\n",
                        "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/segment-anything-2.git'\": Expected package name at the start of dependency specifier\n",
                        "    'git+https://github.com/facebookresearch/segment-anything-2.git'\n",
                        "    ^\n"
                    ]
                }
            ],
            "source": [
                "# Instalación de dependencias (Asegurar última versión de ultralytics para soporte SAM 3)\n",
                "!pip install -U -q ultralytics pandas matplotlib opencv-python seaborn scikit-learn pillow tqdm ftfy\n",
                "!pip install -q 'git+https://github.com/facebookresearch/segment-anything-2.git'  # Dependencias base"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dispositivo: cpu\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import cv2\n",
                "import torch\n",
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from ultralytics import YOLO, SAM\n",
                "from ultralytics.utils.metrics import box_iou\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "from scipy.ndimage import binary_fill_holes, binary_erosion, binary_dilation\n",
                "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Dispositivo: {device}\")\n",
                "if device == 'cuda':\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "# Configuración de visualización\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.dpi'] = 100\n",
                "plt.rcParams['font.size'] = 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Sistema de Caché (Independiente)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PredictionCache:\n",
                "    \"\"\"Caché para almacenar predicciones YOLO y evitar recálculos.\"\"\"\n",
                "    \n",
                "    def __init__(self, cache_file='yolo_predictions_cache_sam3.pkl'):\n",
                "        self.cache_file = cache_file\n",
                "        self.cache = self._load_cache()\n",
                "    \n",
                "    def _load_cache(self):\n",
                "        if os.path.exists(self.cache_file):\n",
                "            with open(self.cache_file, 'rb') as f:\n",
                "                return pickle.load(f)\n",
                "        return {}\n",
                "    \n",
                "    def save(self):\n",
                "        with open(self.cache_file, 'wb') as f:\n",
                "            pickle.dump(self.cache, f)\n",
                "    \n",
                "    def get(self, image_path):\n",
                "        return self.cache.get(str(image_path))\n",
                "    \n",
                "    def set(self, image_path, predictions):\n",
                "        self.cache[str(image_path)] = predictions\n",
                "    \n",
                "    def clear(self):\n",
                "        self.cache = {}\n",
                "        if os.path.exists(self.cache_file):\n",
                "            os.remove(self.cache_file)\n",
                "\n",
                "pred_cache = PredictionCache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Carga de Modelos (SAM 3 REAL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cargando YOLO: ./modelos_entrenados/modelo-acuatico-m.pt...\n",
                        "✓ YOLO cargado\n",
                        "\n",
                        "Intentando cargar SAM 3...\n",
                        "Intentando descargar/cargar sam3_b.pt...\n",
                        "  - Falló sam3_b.pt: No module named 'ftfy'...\n",
                        "Intentando descargar/cargar sam3_t.pt...\n",
                        "  - Falló sam3_t.pt: No module named 'ftfy'...\n",
                        "Intentando descargar/cargar sam3_l.pt...\n",
                        "  - Falló sam3_l.pt: No module named 'ftfy'...\n",
                        "\n",
                        "⚠️ ADVERTENCIA: No se pudo cargar SAM 3. Intentando SAM 2.1 como fallback...\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "No se pudo cargar ningún modelo SAM. Intenta reiniciar el kernel para liberar memoria.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[4], line 54\u001b[0m\n\u001b[0;32m     53\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m---> 54\u001b[0m model_sam \u001b[38;5;241m=\u001b[39m SAM(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msam2.1_b.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Usar Base para evitar MemoryError\u001b[39;00m\n\u001b[0;32m     55\u001b[0m sam_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msam2.1_b\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\model.py:63\u001b[0m, in \u001b[0;36mSAM.__init__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sam3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msam3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m Path(model)\u001b[38;5;241m.\u001b[39mstem\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:144\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(model, task\u001b[38;5;241m=\u001b[39mtask)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\model.py:83\u001b[0m, in \u001b[0;36mSAM._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_sam  \u001b[38;5;66;03m# slow import\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m build_sam(weights)\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\build.py:365\u001b[0m, in \u001b[0;36mbuild_sam\u001b[1;34m(ckpt)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a supported SAM model. Available models are: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msam_model_map\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_builder(ckpt)\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\build.py:112\u001b[0m, in \u001b[0;36mbuild_sam2_b\u001b[1;34m(checkpoint)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build and return a Segment Anything Model 2 (SAM2) base-size model with specified architecture parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _build_sam2(\n\u001b[0;32m    113\u001b[0m     encoder_embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m112\u001b[39m,\n\u001b[0;32m    114\u001b[0m     encoder_stages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m    115\u001b[0m     encoder_num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    116\u001b[0m     encoder_global_att_blocks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m    117\u001b[0m     encoder_window_spec\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m    118\u001b[0m     encoder_window_spatial_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m14\u001b[39m],\n\u001b[0;32m    119\u001b[0m     encoder_backbone_channel_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m896\u001b[39m, \u001b[38;5;241m448\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m112\u001b[39m],\n\u001b[0;32m    120\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint,\n\u001b[0;32m    121\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\build.py:314\u001b[0m, in \u001b[0;36m_build_sam2\u001b[1;34m(encoder_embed_dim, encoder_stages, encoder_num_heads, encoder_global_att_blocks, encoder_backbone_channel_list, encoder_window_spatial_size, encoder_window_spec, checkpoint)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     sam2 \u001b[38;5;241m=\u001b[39m _load_checkpoint(sam2, checkpoint)\n\u001b[0;32m    315\u001b[0m sam2\u001b[38;5;241m.\u001b[39meval()\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\sam\\build.py:29\u001b[0m, in \u001b[0;36m_load_checkpoint\u001b[1;34m(model, checkpoint)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 29\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m attempt_download_asset(checkpoint)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\downloads.py:467\u001b[0m, in \u001b[0;36mattempt_download_asset\u001b[1;34m(file, repo, release, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m repo \u001b[38;5;241m==\u001b[39m GITHUB_ASSETS_REPO \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m GITHUB_ASSETS_NAMES:\n\u001b[1;32m--> 467\u001b[0m     safe_download(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelease\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39mfile, min_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e5\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\downloads.py:335\u001b[0m, in \u001b[0;36msafe_download\u001b[1;34m(url, file, dir, unzip, delete, curl, retry, min_bytes, exist_ok, progress)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m expected_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1048576\u001b[39m:\n\u001b[1;32m--> 335\u001b[0m     check_disk_space(expected_size, path\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m    336\u001b[0m buffer_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m8192\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1048576\u001b[39m, expected_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m expected_size \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m8192\u001b[39m\n",
                        "File \u001b[1;32mc:\\Users\\lbuln\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\downloads.py:230\u001b[0m, in \u001b[0;36mcheck_disk_space\u001b[1;34m(file_bytes, path, sf, hard)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hard:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m(text)\n\u001b[0;32m    231\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mwarning(text)\n",
                        "\u001b[1;31mMemoryError\u001b[0m: Insufficient free disk space 0.000 GB < 0.000 GB required, Please free 0.000 GB additional disk space and try again.",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[4], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Fallback: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msam_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cargado\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo se pudo cargar ningún modelo SAM. Intenta reiniciar el kernel para liberar memoria.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m→ Modelo activo para pruebas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msam_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: No se pudo cargar ningún modelo SAM. Intenta reiniciar el kernel para liberar memoria."
                    ]
                }
            ],
            "source": [
                "# Rutas\n",
                "TEST_IMAGES_DIR = Path('./dataset_yolo/images/test')\n",
                "TEST_LABELS_DIR = Path('./dataset_yolo/labels/test')\n",
                "RESULTS_DIR = Path('./resultados_sam3_real')\n",
                "RESULTS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "# Cargar YOLO (Modelo Base)\n",
                "import glob\n",
                "yolo_candidates = [\n",
                "    './modelos_entrenados/modelo-acuatico-m.pt',\n",
                "    './modelos_entrenados/modelo-mixto-m.pt',\n",
                "    *glob.glob('./modelos_entrenados/*-m.pt')\n",
                "]\n",
                "MODELO_YOLO_PATH = next((p for p in yolo_candidates if os.path.exists(p)), None)\n",
                "if not MODELO_YOLO_PATH:\n",
                "    raise FileNotFoundError(\"No se encontró modelo YOLO Medium\")\n",
                "\n",
                "print(f\"Cargando YOLO: {MODELO_YOLO_PATH}...\")\n",
                "model_yolo = YOLO(MODELO_YOLO_PATH)\n",
                "print(\"✓ YOLO cargado\")\n",
                "\n",
                "# Cargar SAM 3 (REAL) con manejo de memoria\n",
                "print(\"\\nIntentando cargar SAM 3...\")\n",
                "sam_models = {}\n",
                "# Lista de prioridad para SAM 3 - Priorizamos modelos más ligeros para evitar MemoryError\n",
                "sam_candidates = [\n",
                "    'sam3_b.pt',   # SAM 3 Base (Recomendado por memoria)\n",
                "    'sam3_t.pt',   # SAM 3 Tiny (Fallback ligero)\n",
                "    'sam3_l.pt',   # SAM 3 Large (Solo si hay mucha RAM/VRAM)\n",
                "]\n",
                "\n",
                "model_sam = None\n",
                "sam_name = \"\"\n",
                "\n",
                "for weight in sam_candidates:\n",
                "    try:\n",
                "        print(f\"Intentando descargar/cargar {weight}...\")\n",
                "        if device == 'cuda':\n",
                "            torch.cuda.empty_cache()\n",
                "        model_sam = SAM(weight)\n",
                "        sam_name = weight.replace('.pt', '')\n",
                "        print(f\"✓ ÉXITO: {sam_name.upper()} cargado correctamente\")\n",
                "        break\n",
                "    except MemoryError:\n",
                "        print(f\"  - Falló {weight}: Memoria insuficiente (MemoryError)\")\n",
                "    except Exception as e:\n",
                "        print(f\"  - Falló {weight}: {str(e)[:100]}...\")\n",
                "\n",
                "if model_sam is None:\n",
                "    print(\"\\n⚠️ ADVERTENCIA: No se pudo cargar SAM 3. Intentando SAM 2.1 como fallback...\")\n",
                "    try:\n",
                "        if device == 'cuda':\n",
                "            torch.cuda.empty_cache()\n",
                "        model_sam = SAM('sam2.1_b.pt') # Usar Base para evitar MemoryError\n",
                "        sam_name = 'sam2.1_b'\n",
                "        print(f\"✓ Fallback: {sam_name.upper()} cargado\")\n",
                "    except:\n",
                "        raise RuntimeError(\"No se pudo cargar ningún modelo SAM. Intenta reiniciar el kernel para liberar memoria.\")\n",
                "\n",
                "print(f\"\\n→ Modelo activo para pruebas: {sam_name.upper()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Funciones de Utilidad (Optimizadas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def read_yolo_labels(label_path, img_width, img_height):\n",
                "    \"\"\"Lee etiquetas YOLO y retorna [class, x1, y1, x2, y2].\"\"\"\n",
                "    boxes = []\n",
                "    if not os.path.exists(label_path):\n",
                "        return np.array([])\n",
                "    \n",
                "    with open(label_path, 'r') as f:\n",
                "        for line in f:\n",
                "            parts = list(map(float, line.strip().split()))\n",
                "            cls, x_c, y_c, w, h = parts\n",
                "            x1 = (x_c - w/2) * img_width\n",
                "            y1 = (y_c - h/2) * img_height\n",
                "            x2 = (x_c + w/2) * img_width\n",
                "            y2 = (y_c + h/2) * img_height\n",
                "            boxes.append([int(cls), x1, y1, x2, y2])\n",
                "    \n",
                "    return np.array(boxes) if boxes else np.array([])\n",
                "\n",
                "def mask_to_box(mask):\n",
                "    \"\"\"Convierte máscara a box [x1, y1, x2, y2].\"\"\"\n",
                "    y_indices, x_indices = np.where(mask > 0)\n",
                "    if len(x_indices) == 0:\n",
                "        return None\n",
                "    return [np.min(x_indices), np.min(y_indices), \n",
                "            np.max(x_indices), np.max(y_indices)]\n",
                "\n",
                "def postprocess_mask(mask, min_area=50):\n",
                "    \"\"\"Post-procesamiento suave (solo dilatación).\"\"\"\n",
                "    filled = binary_fill_holes(mask)\n",
                "    opened = binary_dilation(filled)\n",
                "    if np.sum(opened) < min_area:\n",
                "        return mask\n",
                "    return opened.astype(np.uint8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Estrategias de Refinamiento (SAM 3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def refine_basic(img, yolo_boxes, sam_model):\n",
                "    \"\"\"Estrategia 1: SAM con box prompts.\"\"\"\n",
                "    if len(yolo_boxes) == 0:\n",
                "        return yolo_boxes\n",
                "    \n",
                "    prompts = yolo_boxes[:, :4]\n",
                "    # SAM 3 soporta batch inference nativo\n",
                "    results = sam_model(img, bboxes=prompts, verbose=False)[0]\n",
                "    \n",
                "    refined_boxes = []\n",
                "    if results.masks is not None:\n",
                "        for i, mask in enumerate(results.masks.data.cpu().numpy()):\n",
                "            box = mask_to_box(mask)\n",
                "            if box:\n",
                "                refined_boxes.append(box + [yolo_boxes[i, 4], yolo_boxes[i, 5]])\n",
                "            else:\n",
                "                refined_boxes.append(yolo_boxes[i].tolist())\n",
                "    else:\n",
                "        refined_boxes = yolo_boxes.tolist()\n",
                "    \n",
                "    return np.array(refined_boxes)\n",
                "\n",
                "def refine_adaptive(img, yolo_boxes, sam_model, conf_threshold=0.25):\n",
                "    \"\"\"Estrategia 2: SAM solo en detecciones de confianza media-alta.\"\"\"\n",
                "    if len(yolo_boxes) == 0:\n",
                "        return yolo_boxes\n",
                "    \n",
                "    refined_boxes = []\n",
                "    high_conf_boxes = yolo_boxes[yolo_boxes[:, 4] >= conf_threshold]\n",
                "    \n",
                "    if len(high_conf_boxes) > 0:\n",
                "        prompts = high_conf_boxes[:, :4]\n",
                "        results = sam_model(img, bboxes=prompts, verbose=False)[0]\n",
                "        \n",
                "        if results.masks is not None:\n",
                "            for i, mask in enumerate(results.masks.data.cpu().numpy()):\n",
                "                box = mask_to_box(mask)\n",
                "                if box:\n",
                "                    refined_boxes.append(box + [high_conf_boxes[i, 4], high_conf_boxes[i, 5]])\n",
                "                else:\n",
                "                    refined_boxes.append(high_conf_boxes[i].tolist())\n",
                "    \n",
                "    low_conf_boxes = yolo_boxes[yolo_boxes[:, 4] < conf_threshold]\n",
                "    if len(low_conf_boxes) > 0:\n",
                "        refined_boxes.extend(low_conf_boxes.tolist())\n",
                "    \n",
                "    return np.array(refined_boxes) if refined_boxes else yolo_boxes\n",
                "\n",
                "def refine_postprocess(img, yolo_boxes, sam_model):\n",
                "    \"\"\"Estrategia 3: SAM + Post-procesamiento.\"\"\"\n",
                "    if len(yolo_boxes) == 0:\n",
                "        return yolo_boxes\n",
                "    \n",
                "    prompts = yolo_boxes[:, :4]\n",
                "    results = sam_model(img, bboxes=prompts, verbose=False)[0]\n",
                "    \n",
                "    refined_boxes = []\n",
                "    if results.masks is not None:\n",
                "        for i, mask in enumerate(results.masks.data.cpu().numpy()):\n",
                "            processed_mask = postprocess_mask(mask)\n",
                "            box = mask_to_box(processed_mask)\n",
                "            if box:\n",
                "                refined_boxes.append(box + [yolo_boxes[i, 4], yolo_boxes[i, 5]])\n",
                "            else:\n",
                "                refined_boxes.append(yolo_boxes[i].tolist())\n",
                "    else:\n",
                "        refined_boxes = yolo_boxes.tolist()\n",
                "    \n",
                "    return np.array(refined_boxes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluación"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_batch_stats(predictions, targets, iou_threshold=0.5):\n",
                "    \"\"\"Calcula estadísticas TP/FP.\"\"\"\n",
                "    if len(predictions) == 0:\n",
                "        return []\n",
                "    if len(targets) == 0:\n",
                "        return [[0, float(pred[4]), float(pred[5]), 0.0] for pred in predictions]\n",
                "    \n",
                "    pred_boxes = torch.tensor(predictions[:, :4], dtype=torch.float32)\n",
                "    target_boxes = torch.tensor(targets[:, 1:], dtype=torch.float32)\n",
                "    ious = box_iou(pred_boxes, target_boxes)\n",
                "    \n",
                "    stats = []\n",
                "    detected_targets = set()\n",
                "    sorted_indices = np.argsort(-predictions[:, 4])\n",
                "    \n",
                "    for idx in sorted_indices:\n",
                "        pred = predictions[idx]\n",
                "        iou_row = ious[idx]\n",
                "        best_iou, best_target_idx = 0, -1\n",
                "        \n",
                "        for t_idx, iou in enumerate(iou_row):\n",
                "            if t_idx not in detected_targets and targets[t_idx, 0] == pred[5]:\n",
                "                if iou > best_iou:\n",
                "                    best_iou, best_target_idx = iou, t_idx\n",
                "        \n",
                "        if best_iou >= iou_threshold:\n",
                "            detected_targets.add(best_target_idx)\n",
                "            stats.append([1, pred[4], pred[5], float(best_iou)])\n",
                "        else:\n",
                "            stats.append([0, pred[4], pred[5], 0.0])\n",
                "    \n",
                "    return stats\n",
                "\n",
                "def compute_pr_metrics(stats, total_gt):\n",
                "    \"\"\"Calcula métricas finales.\"\"\"\n",
                "    if len(stats) == 0:\n",
                "        return {'precision': 0, 'recall': 0, 'f1': 0, 'mAP': 0, 'avg_iou': 0}\n",
                "    \n",
                "    stats = np.array(stats)\n",
                "    stats = stats[np.argsort(-stats[:, 1])]\n",
                "    \n",
                "    tp = stats[:, 0]\n",
                "    fp = 1 - tp\n",
                "    tp_cumsum = np.cumsum(tp)\n",
                "    fp_cumsum = np.cumsum(fp)\n",
                "    \n",
                "    precision = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-16)\n",
                "    recall = tp_cumsum / (total_gt + 1e-16)\n",
                "    f1 = 2 * (precision * recall) / (precision + recall + 1e-16)\n",
                "    \n",
                "    # mAP\n",
                "    recall_thresholds = np.linspace(0, 1, 11)\n",
                "    precision_interpolated = np.zeros(11)\n",
                "    for i, r in enumerate(recall_thresholds):\n",
                "        precisions_at_recall = precision[recall >= r]\n",
                "        precision_interpolated[i] = np.max(precisions_at_recall) if len(precisions_at_recall) > 0 else 0\n",
                "    mAP = np.mean(precision_interpolated)\n",
                "    \n",
                "    best_idx = np.argmax(f1) if len(f1) > 0 else 0\n",
                "    tp_indices = stats[:, 0] == 1\n",
                "    avg_iou = np.mean(stats[tp_indices, 3]) if np.any(tp_indices) else 0\n",
                "    \n",
                "    return {\n",
                "        'precision': precision[best_idx],\n",
                "        'recall': recall[best_idx],\n",
                "        'f1': f1[best_idx],\n",
                "        'mAP': mAP,\n",
                "        'avg_iou': avg_iou\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ejecutar Evaluación\n",
                "image_files = sorted(list(TEST_IMAGES_DIR.glob('*.jpg')) + list(TEST_IMAGES_DIR.glob('*.png')))\n",
                "stats_collections = {'yolo': [], 'sam_basic': [], 'sam_adaptive': [], 'sam_postprocess': []}\n",
                "total_gt = 0\n",
                "\n",
                "print(f\"Evaluando {len(image_files)} imágenes con {sam_name.upper()}...\")\n",
                "\n",
                "for img_path in tqdm(image_files):\n",
                "    img = cv2.imread(str(img_path))\n",
                "    if img is None: continue\n",
                "    \n",
                "    h, w = img.shape[:2]\n",
                "    label_path = TEST_LABELS_DIR / (img_path.stem + '.txt')\n",
                "    gt_boxes = read_yolo_labels(label_path, w, h)\n",
                "    if len(gt_boxes) > 0: total_gt += len(gt_boxes)\n",
                "    \n",
                "    # YOLO (con conf=0.25)\n",
                "    cached_pred = pred_cache.get(img_path)\n",
                "    if cached_pred is not None:\n",
                "        yolo_boxes = cached_pred\n",
                "    else:\n",
                "        results = model_yolo(img, conf=0.25, iou=0.45, verbose=False)[0]\n",
                "        yolo_boxes = results.boxes.data.cpu().numpy()\n",
                "        pred_cache.set(img_path, yolo_boxes)\n",
                "    \n",
                "    stats_collections['yolo'].extend(calculate_batch_stats(yolo_boxes, gt_boxes))\n",
                "    \n",
                "    # SAM Strategies\n",
                "    stats_collections['sam_basic'].extend(calculate_batch_stats(refine_basic(img, yolo_boxes, model_sam), gt_boxes))\n",
                "    stats_collections['sam_adaptive'].extend(calculate_batch_stats(refine_adaptive(img, yolo_boxes, model_sam), gt_boxes))\n",
                "    stats_collections['sam_postprocess'].extend(calculate_batch_stats(refine_postprocess(img, yolo_boxes, model_sam), gt_boxes))\n",
                "\n",
                "pred_cache.save()\n",
                "print(\"✓ Evaluación completada\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resultados\n",
                "results = {}\n",
                "for name, stats in stats_collections.items():\n",
                "    results[name] = compute_pr_metrics(stats, total_gt)\n",
                "\n",
                "df_results = pd.DataFrame({\n",
                "    'Estrategia': ['YOLO Base', 'SAM 3 Básico', 'SAM 3 Adaptativo', 'SAM 3 Post-Proc.'],\n",
                "    'F1-Score': [results['yolo']['f1'], results['sam_basic']['f1'], results['sam_adaptive']['f1'], results['sam_postprocess']['f1']],\n",
                "    'mAP@0.5': [results['yolo']['mAP'], results['sam_basic']['mAP'], results['sam_adaptive']['mAP'], results['sam_postprocess']['mAP']],\n",
                "    'IoU Prom.': [results['yolo']['avg_iou'], results['sam_basic']['avg_iou'], results['sam_adaptive']['avg_iou'], results['sam_postprocess']['avg_iou']]\n",
                "})\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(f\"RESULTADOS SAM 3 REAL ({sam_name.upper()})\")\n",
                "print(\"=\"*80)\n",
                "print(df_results.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
                "print(\"=\"*80)\n",
                "\n",
                "df_results.to_csv(RESULTS_DIR / 'metricas_sam3.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
