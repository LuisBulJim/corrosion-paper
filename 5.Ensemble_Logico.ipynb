{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estrategia: El Ensemble \"L√≥gico\" (WBF) y Evaluaci√≥n Comparativa\n",
    "\n",
    "Este notebook implementa la estrategia de combinaci√≥n de modelos utilizando **Weighted Box Fusion (WBF)** y compara sus m√©tricas (mAP, Precisi√≥n, Recall) con los modelos individuales.\n",
    "\n",
    "### Los Modelos\n",
    "1. **El Especialista (Acuatico-Nano):** Alta Precisi√≥n, bajo Recall. (Peso: 2)\n",
    "2. **El Sabueso (Acuatico-Medium):** Bajo Precisi√≥n, alto Recall. (Peso: 1)\n",
    "\n",
    "### La Estrategia (WBF)\n",
    "*   **Weighted Box Fusion (WBF)** combina predicciones ponderadas.\n",
    "*   Prioridad al **Acuatico-Nano** (2:1) para mantener precisi√≥n.\n",
    "*   El **Acuatico-Medium** mejora el Recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Nano: True\n",
      "Modelo Medium: True\n",
      "Labels Test: True\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURACI√ìN ---\n",
    "PATH_NANO = 'modelos_entrenados/modelo-acuatico-n.pt'\n",
    "PATH_MEDIUM = 'modelos_entrenados/modelo-acuatico-m.pt'\n",
    "DATASET_YAML = 'dataset_yolo/dataset.yml'\n",
    "TEST_IMAGES_DIR = 'dataset_yolo/images/test'\n",
    "TEST_LABELS_DIR = 'dataset_yolo/labels/test'\n",
    "# Par√°metros del Ensemble\n",
    "WEIGHTS = [2, 1] # [Nano, Medium]\n",
    "IOU_THR = 0.5    # Umbral de WBF\n",
    "SKIP_BOX_THR = 0.001\n",
    "CONF_THR = 0.25\n",
    "\n",
    "# Verificar rutas\n",
    "print(f\"Modelo Nano: {os.path.exists(PATH_NANO)}\")\n",
    "print(f\"Modelo Medium: {os.path.exists(PATH_MEDIUM)}\")\n",
    "print(f\"Labels Test: {os.path.exists(TEST_LABELS_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementaci√≥n del Ensemble (WBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_boxes(results):\n",
    "    \"\"\"\n",
    "    Extrae cajas normalizadas de resultados YOLO.\n",
    "    Retorna listas de boxes, scores y labels.\n",
    "    \"\"\"\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxyn.cpu().numpy()\n",
    "        scores = result.boxes.conf.cpu().numpy()\n",
    "        labels = result.boxes.cls.cpu().numpy()\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        scores_list.append(scores)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return boxes_list, scores_list, labels_list\n",
    "\n",
    "\n",
    "def run_wbf(preds_nano, preds_medium, weights=[2, 1], iou_thr=0.5, skip_thr=0.001):\n",
    "    \"\"\"\n",
    "    Combina predicciones de dos modelos YOLO usando Weighted Boxes Fusion (WBF).\n",
    "    \"\"\"\n",
    "    # Preparar predicciones\n",
    "    b1, s1, l1 = prepare_boxes(preds_nano)\n",
    "    b2, s2, l2 = prepare_boxes(preds_medium)\n",
    "\n",
    "    # WBF solo funciona con listas de listas -> extraemos el batch 0\n",
    "    boxes_list = [b1[0], b2[0]]\n",
    "    scores_list = [s1[0], s2[0]]\n",
    "    labels_list = [l1[0], l2[0]]\n",
    "\n",
    "    # Aplicar fusi√≥n ponderada\n",
    "    boxes, scores, labels = weighted_boxes_fusion(\n",
    "        boxes_list,\n",
    "        scores_list,\n",
    "        labels_list,\n",
    "        weights=weights,\n",
    "        iou_thr=iou_thr,\n",
    "        skip_box_thr=skip_thr\n",
    "    )\n",
    "\n",
    "    return boxes, scores, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Herramientas de Evaluaci√≥n Personalizada (mAP Calculator)Dado que el Ensemble no es un modelo YOLO est√°ndar, implementamos un calculador de m√©tricas (mAP50, mAP50-95) para evaluar sus predicciones contra el Ground Truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPCalculator:\n",
    "    \"\"\"Calculadora simple de mAP para una sola clase (Corrosi√≥n).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "\n",
    "    def update(self, pred_boxes, pred_scores, target_boxes):\n",
    "        \"\"\"\n",
    "        Acumula predicciones y targets por imagen.\n",
    "        pred_boxes: [[x1, y1, x2, y2], ...]\n",
    "        target_boxes: [[x1, y1, x2, y2], ...]\n",
    "        \"\"\"\n",
    "        self.predictions.append({'boxes': pred_boxes, 'scores': pred_scores})\n",
    "        self.targets.append(target_boxes)\n",
    "\n",
    "    def compute_iou(self, box1, box2):\n",
    "        \"\"\"Calcula IoU entre dos cajas (formato x1, y1, x2, y2).\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "    def compute_ap(self, iou_threshold):\n",
    "        \"\"\"Calcula Average Precision de forma robusta.\"\"\"\n",
    "        all_scores = []\n",
    "        all_tps = []\n",
    "        total_gt = 0\n",
    "\n",
    "        # 1. Aplanar listas de forma segura\n",
    "        for preds, targets in zip(self.predictions, self.targets):\n",
    "            total_gt += len(targets)\n",
    "            if len(preds['boxes']) == 0:\n",
    "                continue\n",
    "            \n",
    "            p_boxes = preds['boxes']\n",
    "            p_scores = preds['scores']\n",
    "            \n",
    "            # Ordenar por imagen para matching\n",
    "            sorted_idx = np.argsort(-p_scores)\n",
    "            p_boxes = p_boxes[sorted_idx]\n",
    "            p_scores = p_scores[sorted_idx]\n",
    "            \n",
    "            tp = np.zeros(len(p_boxes))\n",
    "            detected_gt = np.zeros(len(targets))\n",
    "            \n",
    "            for i, p_box in enumerate(p_boxes):\n",
    "                best_iou = 0\n",
    "                best_gt_idx = -1\n",
    "                for j, t_box in enumerate(targets):\n",
    "                    iou = self.compute_iou(p_box, t_box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = j\n",
    "                \n",
    "                if best_iou >= iou_threshold and not detected_gt[best_gt_idx]:\n",
    "                    tp[i] = 1\n",
    "                    detected_gt[best_gt_idx] = 1\n",
    "            \n",
    "            all_scores.extend(p_scores)\n",
    "            all_tps.extend(tp)\n",
    "\n",
    "        # 2. Short-circuit si no hay Ground Truth o Predicciones\n",
    "        if total_gt == 0 or len(all_scores) == 0:\n",
    "            return 0.0, 0.0, 0.0\n",
    "\n",
    "        # 3. Conversi√≥n a NumPy expl√≠cita\n",
    "        all_scores = np.array(all_scores)\n",
    "        all_tps = np.array(all_tps)\n",
    "\n",
    "        # Ordenar globalmente\n",
    "        sorted_indices = np.argsort(-all_scores)\n",
    "        all_tps = all_tps[sorted_indices]\n",
    "\n",
    "        # 4. C√°lculo de m√©tricas acumuladas\n",
    "        cum_tp = np.cumsum(all_tps)\n",
    "        cum_fp = np.cumsum(1 - all_tps)\n",
    "\n",
    "        # Evitar divisi√≥n por cero con epsilons\n",
    "        precision = cum_tp / (cum_tp + cum_fp + 1e-16)\n",
    "        recall = cum_tp / (total_gt + 1e-16)\n",
    "\n",
    "        # 5. Construcci√≥n de Centinelas (El punto cr√≠tico)\n",
    "        # Concatenamos expl√≠citamente y verificamos formas si fuera necesario\n",
    "        mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "        mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "        # Compute the precision envelope\n",
    "        mpre = np.maximum.accumulate(mpre[::-1])[::-1]\n",
    "\n",
    "        # M√©todo de integraci√≥n (Area Under Curve)\n",
    "        # Buscamos puntos donde cambia el recall (eje X)\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # (mrec[i + 1] - mrec[i]) es el ancho del paso\n",
    "        # mpre[i + 1] es la altura (precisi√≥n rectificada)\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "\n",
    "        # Extraer m√©tricas puntuales (F1 m√°ximo)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-16)\n",
    "        best_idx = np.argmax(f1) if len(f1) > 0 else 0\n",
    "\n",
    "        # Retornamos el valor del mejor punto operativo\n",
    "        return ap, precision[best_idx], recall[best_idx]\n",
    "\n",
    "    def compute_metrics(self):\n",
    "        \"\"\"Calcula mAP50 y mAP50-95.\"\"\"\n",
    "        print(\"Calculando m√©tricas...\")\n",
    "\n",
    "        ap50, p50, r50 = self.compute_ap(0.5)\n",
    "\n",
    "        aps = []\n",
    "        for thr in np.arange(0.5, 0.96, 0.05):\n",
    "            ap, _, _ = self.compute_ap(thr)\n",
    "            aps.append(ap)\n",
    "\n",
    "        map50_95 = np.mean(aps)\n",
    "        f1 = 2 * p50 * r50 / (p50 + r50 + 1e-16)\n",
    "\n",
    "        return {\n",
    "            'mAP50-95': map50_95,\n",
    "            'mAP50': ap50,\n",
    "            'Precisi√≥n': p50,\n",
    "            'Recall': r50,\n",
    "            'F1-Score': f1\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ejecuci√≥n de la Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelos\n",
    "model_nano = YOLO(PATH_NANO)\n",
    "model_medium = YOLO(PATH_MEDIUM)# Lista para guardar resultados\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Acuatico-Nano ---\n",
      "Ultralytics 8.3.228 üöÄ Python-3.9.13 torch-2.8.0+cu128 CPU (AMD Ryzen 7 5800X 8-Core Processor)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2199.3¬±268.5 MB/s, size: 27.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/user/work/EONSEA/Articulo-Corrosion/dataset_yolo/labels/test... 21 images, 12 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.8Kit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /home/user/work/EONSEA/Articulo-Corrosion/dataset_yolo/labels is not writable, cache not saved.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 1.4it/s 2.2s2.0s\n",
      "                   all         33         52      0.905      0.548      0.735      0.436\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/user/work/EONSEA/Articulo-Corrosion/runs/detect/val56\u001b[0m\n",
      "--- Evaluando Acuatico-Medium ---\n",
      "Ultralytics 8.3.228 üöÄ Python-3.9.13 torch-2.8.0+cu128 CPU (AMD Ryzen 7 5800X 8-Core Processor)\n",
      "YOLOv12m summary (fused): 169 layers, 20,105,683 parameters, 0 gradients, 67.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2179.4¬±899.6 MB/s, size: 30.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/user/work/EONSEA/Articulo-Corrosion/dataset_yolo/labels/test... 21 images, 12 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 4.0Kit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /home/user/work/EONSEA/Articulo-Corrosion/dataset_yolo/labels is not writable, cache not saved.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.4s/it 10.3s9.8ss\n",
      "                   all         33         52       0.78      0.577      0.672      0.396\n",
      "Speed: 1.3ms preprocess, 307.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/user/work/EONSEA/Articulo-Corrosion/runs/detect/val57\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def evaluar_modelo_individual(model, nombre):\n",
    "    \"\"\"Eval√∫a un modelo individual usando ultralytics.\"\"\"\n",
    "    print(f\"--- Evaluando {nombre} ---\")\n",
    "\n",
    "    metrics = model.val(data=DATASET_YAML, split='test', verbose=False)\n",
    "\n",
    "    res = {\n",
    "        'Modelo': nombre,\n",
    "        'mAP50-95': metrics.box.map,\n",
    "        'mAP50': metrics.box.map50,\n",
    "        'Precisi√≥n': metrics.box.p[0] if len(metrics.box.p) > 0 else 0,\n",
    "        'Recall': metrics.box.r[0] if len(metrics.box.r) > 0 else 0,\n",
    "        'F1-Score': metrics.box.f1[0] if len(metrics.box.f1) > 0 else 0\n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# 1. Evaluar Individuales\n",
    "resultados.append(evaluar_modelo_individual(model_nano, 'Acuatico-Nano'))\n",
    "resultados.append(evaluar_modelo_individual(model_medium, 'Acuatico-Medium'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Ensemble (WBF) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071bf614d90542d78a54e3cf0c364228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando Ensemble:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando m√©tricas...\n"
     ]
    }
   ],
   "source": [
    "def evaluar_ensemble(model1, model2, dataset_dir, labels_dir):\n",
    "    \"\"\"Eval√∫a el Ensemble manualmente utilizando WBF.\"\"\"\n",
    "    print(\"--- Evaluando Ensemble (WBF) ---\")\n",
    "\n",
    "    calc = MAPCalculator()\n",
    "\n",
    "    # Obtener lista de im√°genes\n",
    "    image_files = glob.glob(os.path.join(dataset_dir, '*.jpg'))\n",
    "    glob.glob(os.path.join(dataset_dir, '*.png'))\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Procesando Ensemble\"):\n",
    "\n",
    "        # 1. Inferencia de ambos modelos\n",
    "        r1 = model1.predict(img_path, conf=CONF_THR, verbose=False)\n",
    "        r2 = model2.predict(img_path, conf=CONF_THR, verbose=False)\n",
    "\n",
    "        # 2. Fusi√≥n WBF\n",
    "        boxes, scores, labels = run_wbf(\n",
    "            r1, r2,\n",
    "            weights=WEIGHTS,\n",
    "            iou_thr=IOU_THR,\n",
    "            skip_thr=SKIP_BOX_THR\n",
    "        )\n",
    "\n",
    "        # 3. Cargar Ground Truth\n",
    "        label_name = os.path.basename(img_path).rsplit('.', 1)[0] + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_name)\n",
    "\n",
    "        gt_boxes = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = list(map(float, line.strip().split()))\n",
    "                    cls, xc, yc, w, h = parts\n",
    "\n",
    "                    x1 = xc - w / 2\n",
    "                    y1 = yc - h / 2\n",
    "                    x2 = xc + w / 2\n",
    "                    y2 = yc + h / 2\n",
    "\n",
    "                    gt_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            gt_boxes = np.array(gt_boxes)\n",
    "\n",
    "        # 4. Actualizar m√©tricas solo si hay predicciones\n",
    "        if len(boxes) > 0:\n",
    "            calc.update(boxes, scores, gt_boxes)\n",
    "\n",
    "    # Calcular m√©tricas finales despu√©s de procesar todas las im√°genes\n",
    "    metrics = calc.compute_metrics()\n",
    "    metrics['Modelo'] = 'Ensemble (WBF 2:1)'\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# 2. Evaluar Ensemble\n",
    "try:\n",
    "    res_ensemble = evaluar_ensemble(\n",
    "        model_nano,\n",
    "        model_medium,\n",
    "        TEST_IMAGES_DIR,\n",
    "        TEST_LABELS_DIR\n",
    "    )\n",
    "    resultados.append(res_ensemble)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en evaluaci√≥n del Ensemble: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizaci√≥n de Hiperpar√°metros (Grid Search)\n",
    "B√∫squeda exhaustiva para encontrar la mejor combinaci√≥n de pesos, umbral IoU y umbral de confianza para maximizar el F1-Score y mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando 48 combinaciones...\n",
      "Pre-calculando inferencias...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dba0585a374970b90b692879d46d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Caching Inferences:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c2432b159a4c57a00d45488bb8fd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 5 Mejores Configuraciones (por F1-Score) ---\n",
      "   weights  iou_thr  conf_thr  mAP50-95     mAP50  Precisi√≥n  Recall  F1-Score\n",
      "1   [1, 1]     0.45       0.3  0.442033  0.698175   0.969697    0.64  0.771084\n",
      "16  [2, 1]     0.50       0.3  0.434643  0.691674   0.916667    0.66  0.767442\n",
      "34  [3, 1]     0.60       0.3  0.425463  0.665652   0.916667    0.66  0.767442\n",
      "28  [3, 1]     0.50       0.3  0.429250  0.686438   0.916667    0.66  0.767442\n",
      "25  [3, 1]     0.45       0.3  0.429250  0.686438   0.916667    0.66  0.767442\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# --- CONFIGURACI√ìN DE B√öSQUEDA ---\n",
    "# Define los rangos de par√°metros a probar\n",
    "search_space = {\n",
    "    'weights': [[1, 1], [2, 1], [3, 1], [1, 2]], # [Nano, Medium]\n",
    "    'iou_thr': [0.45, 0.5, 0.55, 0.6],\n",
    "    'conf_thr': [0.25, 0.30, 0.35]\n",
    "}\n",
    "\n",
    "# Generar todas las combinaciones\n",
    "keys, values = zip(*search_space.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"Probando {len(combinations)} combinaciones...\")\n",
    "\n",
    "results_grid = []\n",
    "\n",
    "# Cargar im√°genes una sola vez para no repetir I/O\n",
    "image_files = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.jpg'))\n",
    "glob.glob(os.path.join(TEST_IMAGES_DIR, '*.png'))\n",
    "\n",
    "# Pre-calcular predicciones crudas para ahorrar tiempo (¬°Clave para velocidad!)\n",
    "# Guardamos las predicciones de cada modelo en memoria\n",
    "print(\"Pre-calculando inferencias...\")\n",
    "preds_cache = []\n",
    "for img_path in tqdm(image_files, desc=\"Caching Inferences\"):\n",
    "    # Usamos un conf bajo (0.01) aqu√≠ para filtrar despu√©s din√°micamente\n",
    "    r1 = model_nano.predict(img_path, conf=0.01, verbose=False)\n",
    "    r2 = model_medium.predict(img_path, conf=0.01, verbose=False) # Nota: Variable model_medium es el Medium\n",
    "\n",
    "    # Cargar GT\n",
    "    label_name = os.path.basename(img_path).rsplit('.', 1)[0] + '.txt'\n",
    "    label_path = os.path.join(TEST_LABELS_DIR, label_name)\n",
    "    gt_boxes = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                cls, xc, yc, w, h = parts\n",
    "\n",
    "                x1 = xc - w / 2\n",
    "                y1 = yc - h / 2\n",
    "                x2 = xc + w / 2\n",
    "                y2 = yc + h / 2\n",
    "\n",
    "                gt_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    preds_cache.append({\n",
    "        'r1': r1,\n",
    "        'r2': r2,\n",
    "        'gt': np.array(gt_boxes)\n",
    "    })\n",
    "\n",
    "def filter_preds(results, conf_lim):\n",
    "    # Funci√≥n auxiliar r√°pida para filtrar por confianza\n",
    "    boxes_list, scores_list, labels_list = [], [], []\n",
    "    for res in results:\n",
    "        b = res.boxes.xyxyn.cpu().numpy()\n",
    "        s = res.boxes.conf.cpu().numpy()\n",
    "        l = res.boxes.cls.cpu().numpy()\n",
    "\n",
    "        mask = s >= conf_lim\n",
    "        boxes_list.append(b[mask])\n",
    "        scores_list.append(s[mask])\n",
    "        labels_list.append(l[mask])\n",
    "    return boxes_list, scores_list, labels_list\n",
    "\n",
    "# --- BUCLE DE OPTIMIZACI√ìN ---\n",
    "for params in tqdm(combinations, desc=\"Grid Search\"):\n",
    "    calc = MAPCalculator()\n",
    "\n",
    "    for item in preds_cache:\n",
    "        # Preparar datos filtrados\n",
    "        b1, s1, l1 = filter_preds(item['r1'], params['conf_thr'])\n",
    "        b2, s2, l2 = filter_preds(item['r2'], params['conf_thr'])\n",
    "\n",
    "        # Ejecutar WBF\n",
    "        if len(b1[0]) == 0 and len(b2[0]) == 0:\n",
    "            boxes, scores = [], []\n",
    "        else:\n",
    "            boxes, scores, labels = weighted_boxes_fusion(\n",
    "                [b1[0], b2[0]],\n",
    "                [s1[0], s2[0]],\n",
    "                [l1[0], l2[0]],\n",
    "                weights=params['weights'],\n",
    "                iou_thr=params['iou_thr'],\n",
    "                skip_box_thr=0.0 # Ya filtramos por conf\n",
    "            )\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            calc.update(boxes, scores, item['gt'])\n",
    "\n",
    "    # Calcular m√©tricas para esta combinaci√≥n\n",
    "    # Silenciamos la salida de 'Calculando m√©tricas...' para no saturar\n",
    "    try:\n",
    "        from io import StringIO \n",
    "        import sys\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = mystdout = StringIO()\n",
    "        \n",
    "        m = calc.compute_metrics()\n",
    "        \n",
    "        sys.stdout = old_stdout\n",
    "    except Exception:\n",
    "        sys.stdout = old_stdout\n",
    "        m = {}\n",
    "\n",
    "    # Guardar\n",
    "    res_entry = params.copy()\n",
    "    res_entry.update(m)\n",
    "    results_grid.append(res_entry)\n",
    "\n",
    "# --- MOSTRAR MEJORES RESULTADOS ---\n",
    "df_grid = pd.DataFrame(results_grid)\n",
    "print(\"--- Top 5 Mejores Configuraciones (por F1-Score) ---\")\n",
    "best_f1_cfg = df_grid.sort_values(by='F1-Score', ascending=False).head(1)\n",
    "print(df_grid.sort_values(by='F1-Score', ascending=False).head(5).to_string())\n",
    "\n",
    "# Agregar el mejor a la tabla de resultados global\n",
    "if not best_f1_cfg.empty:\n",
    "    best_row = best_f1_cfg.iloc[0]\n",
    "    best_res = {\n",
    "        'Modelo': f\"Ensemble Optimizado (W:{best_row['weights']} I:{best_row['iou_thr']} C:{best_row['conf_thr']})\",\n",
    "        'mAP50-95': best_row['mAP50-95'],\n",
    "        'mAP50': best_row['mAP50'],\n",
    "        'Precisi√≥n': best_row['Precisi√≥n'],\n",
    "        'Recall': best_row['Recall'],\n",
    "        'F1-Score': best_row['F1-Score']\n",
    "    }\n",
    "    resultados.append(best_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tabla Final de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TABLA DE RESULTADOS: DATASET ACUATICO ---\n",
      "                                        Modelo  mAP50-95  mAP50  Precisi√≥n  Recall  F1-Score\n",
      "0                                Acuatico-Nano    0.4364 0.7348     0.9047  0.5479    0.6825\n",
      "1  Ensemble Optimizado (W:[1, 1] I:0.45 C:0.3)    0.4420 0.6982     0.9697  0.6400    0.7711\n",
      "2                           Ensemble (WBF 2:1)    0.4065 0.6825     0.8750  0.6731    0.7609\n",
      "3                              Acuatico-Medium    0.3960 0.6724     0.7797  0.5769    0.6632\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TABLA DE RESULTADOS: DATASET ACUATICO ---\")\n",
    "\n",
    "df_res = pd.DataFrame(resultados)\n",
    "\n",
    "if not df_res.empty:\n",
    "\n",
    "    # Ordenar y formatear columnas\n",
    "    cols = ['Modelo', 'mAP50-95', 'mAP50', 'Precisi√≥n', 'Recall', 'F1-Score']\n",
    "    df_res = (\n",
    "        df_res[cols]\n",
    "        .sort_values(by='mAP50', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(df_res.to_string(float_format='{:.4f}'.format))\n",
    "\n",
    "else:\n",
    "    print(\"No se generaron resultados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO1",
   "language": "python",
   "name": "yoloenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
